{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "import sys\n",
    "import os \n",
    "from glob import glob\n",
    "from minio import Minio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- load_cfg from helpers.oy ----------------\n",
    "import yaml\n",
    "\n",
    "def load_cfg(cfg_file):\n",
    "    \"\"\"\n",
    "    Load configuration from a YAML config file\n",
    "    \"\"\"\n",
    "    cfg = None\n",
    "    with open(cfg_file, \"r\") as f:\n",
    "        try:\n",
    "            cfg = yaml.safe_load(f)\n",
    "        except yaml.YAMLError as exc:\n",
    "            print(exc)\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- import MinIOClients from minio_utils.py ----------------\n",
    "\n",
    "class MinIOClient:\n",
    "    def __init__(self, endpoint_url, access_key, secret_key):\n",
    "        self.endpoint_url = endpoint_url\n",
    "        self.access_key = access_key\n",
    "        self.secret_key = secret_key\n",
    "\n",
    "    def create_conn(self):\n",
    "        client = Minio(\n",
    "            endpoint=self.endpoint_url,\n",
    "            access_key=self.access_key,\n",
    "            secret_key=self.secret_key,\n",
    "            secure=False,\n",
    "        )\n",
    "        return client\n",
    "\n",
    "    def create_bucket(self, bucket_name):\n",
    "        client = self.create_conn()\n",
    "        \n",
    "        # Create bucket if not exist\n",
    "        found = client.bucket_exists(bucket_name=bucket_name)\n",
    "        if not found:\n",
    "            client.make_bucket(bucket_name=bucket_name)\n",
    "            print(f\"Bucket {bucket_name} created successfully!\")\n",
    "        else:\n",
    "            print(f\"Bucket {bucket_name} already exists, skip creating!\")\n",
    "\n",
    "    def list_parquet_files(self, bucket_name, prefix=\"\"):\n",
    "        client = self.create_conn()\n",
    "\n",
    "        # List all objects in the bucket with the given prefix\n",
    "        objects = client.list_objects(bucket_name, prefix=prefix, recursive=True)\n",
    "        # Filter and collect Parquet file names\n",
    "        parquet_files = [obj.object_name for obj in objects if obj.object_name.endswith('.parquet')]\n",
    "            \n",
    "        return parquet_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG_FILE = \"../config/datalake.yaml\"\n",
    "YEARS = [\"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]\n",
    "MONTHS = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nyc_data': {'folder_path': 'data'},\n",
       " 'datalake': {'endpoint': 'localhost:9000',\n",
       "  'bucket_name_1': 'raw',\n",
       "  'bucket_name_2': 'processed',\n",
       "  'bucket_name_3': 'sandbox',\n",
       "  'folder_name': 'batch',\n",
       "  'access_key': '0VQBMtMhycuIrat2ivLH',\n",
       "  'secret_key': 'xozBRG1AkxBkEnwN3JePy1BhhvHQGtE1sCAEmZeI'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = load_cfg(CFG_FILE)\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_load(cfg):\n",
    "    datalake_cfg = cfg[\"datalake\"]\n",
    "    nyc_data_cfg = cfg[\"nyc_data\"]\n",
    "    \n",
    "    # Create MinIO client\n",
    "    client = MinIOClient(\n",
    "        endpoint_url=datalake_cfg[\"endpoint\"],\n",
    "        access_key=datalake_cfg[\"access_key\"],\n",
    "        secret_key=datalake_cfg[\"secret_key\"],\n",
    "    )\n",
    "    \n",
    "    client.create_bucket(datalake_cfg[\"bucket_name_1\"])\n",
    "    \n",
    "    # for year in YEARS:\n",
    "    # ...\n",
    "    year = \"2024\"\n",
    "    # Upload files\n",
    "    all_fps = glob(os.path.join(nyc_data_cfg[\"folder_path\"], year, \"*.parquet\"))\n",
    "    for fp in all_fps:\n",
    "        print(f\"Uploading {fp} to MinIO...\")\n",
    "        client_minio = client.create_conn()\n",
    "        client_minio.fput_object(\n",
    "            bucket_name=datalake_cfg[\"bucket_name_1\"],\n",
    "            object_name=os.path.basename(fp),\n",
    "            file_path=fp,\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting and loading data to MinIO...\n",
      "Bucket raw created successfully!\n",
      "Uploading ../data\\2024\\green_tripdata_2024-01.parquet to MinIO...\n",
      "Uploading ../data\\2024\\yellow_tripdata_2024-01.parquet to MinIO...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Extracting and loading data to MinIO...\")\n",
    "    cfg = load_cfg(CFG_FILE)\n",
    "    extract_load(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
